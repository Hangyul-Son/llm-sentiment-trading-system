{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fec66573-9c1b-4f17-bcbe-787ddf067576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the OpenAI API key from environment variables\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Check if the API key is loaded\n",
    "if openai.api_key is None:\n",
    "    raise ValueError(\"API key not found. Please check the .env file.\")\n",
    "else:\n",
    "    print(\"API key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31ba6723-bf59-4f20-9dc8-856319891aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AGIX1U8t70m0jHcKkcgo3xzFU7kA1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This is a test.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1728447847, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=5, prompt_tokens=12, total_tokens=17, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n",
      "This is a test.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Instantiate the client using environment variable for the API key\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Make a chat completion request\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(chat_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebf1e615-b023-4724-9838-708afc0e4f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test.\n"
     ]
    }
   ],
   "source": [
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f842945-caf6-49ee-a682-b90aa99244b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mood_agent(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Analyze the mood of this message, focusing on any hypothetical or speculative language that could affect sentiment: {content}\"\n",
    "        }]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def institutional_investor_agent(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Analyze this message as if you are an institutional investor, focusing on long-term impacts on stability and growth potential: {content}\"\n",
    "        }]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def individual_investor_agent(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Analyze this message as if you are an individual investor, focusing on short-term price impact and immediate gains or losses: {content}\"\n",
    "        }]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def rhetoric_agent(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Analyze the rhetorical style of this message, such as sarcasm, exaggeration, or assertive statements, and how these elements affect sentiment: {content}\"\n",
    "        }]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def dependency_agent(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Focus on the speaker’s sentiment in this message, without considering external perspectives or opinions of third parties: {content}\"\n",
    "        }]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def aspect_agent(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Analyze the sentiment toward the main entity (e.g., company or stock ticker) in this message, ignoring unrelated information: {content}\"\n",
    "        }]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def reference_agent(content):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Identify references to time, price points, or external factors in this message, and analyze how they impact the overall sentiment: {content}\"\n",
    "        }]\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "536e817c-9884-446c-9e84-8725b5b39665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mood_agent: The mood of the message is cautiously optimistic and anticipatory regarding the stock performance of Starbucks ($SBUX). The use of descriptive verbs like \"consolidating\" and \"coiling\" suggests a sense of potential energy and preparation, similar to a spring that is being compressed before it releases. This imagery indicates that the speaker anticipates a significant future movement or change in the stock’s behavior, implying an expectation of upward momentum or a positive breakout.\n",
      "\n",
      "The phrase \"I think many underestimate it\" introduces a speculative element, highlighting the speaker's personal belief that others may not fully recognize the stock's potential. This introduces a contrast between the speaker's viewpoint and the general market perception, suggesting that the speaker sees an overlooked value or opportunity.\n",
      "\n",
      "The final phrase, \"spring how\" appears to be a typographical or textual truncation. Assuming the intended phrase might be something like “spring now” or “spring high,” it aligns with the spring imagery used earlier and emphasizes the expectation of a sudden, positive leap in the stock price, akin to a tightly coiled spring suddenly releasing.\n",
      "\n",
      "Overall, the mood is optimistic, underpinned by a strong belief in the latent potential of Starbucks’ stock, implying a forecast of positive future performance. The speculative language fosters a sentiment of hopeful anticipation and a suggestion that the speaker believes the stock will outperform current market expectations.\n",
      "\n",
      "institutional_investor_agent: As an institutional investor analyzing the message about Starbucks Corporation (Ticker: $SBUX), several key considerations emerge regarding its long-term stability and growth potential:\n",
      "\n",
      "1. **Stock Behavior**: The term \"consolidating and coiling\" generally refers to a stock price that has been trading within a specific range for a considerable time without making significant upward or downward moves. This typically indicates that the stock is under accumulation or distribution, as investors are assessing its value and future potential. For a long-term investor, this behavior could suggest that $SBUX is at a tipping point, potentially preparing for a significant price movement once it breaks out from this consolidation phase.\n",
      "\n",
      "2. **Market Underestimation**: The statement that \"many underestimate it\" suggests that the market might not fully appreciate the company's intrinsic value or its future growth prospects. This could be due to various factors such as temporary challenges, market sentiment, or overshadowing by more volatile stocks. A reassessment of the company's fundamentals, strategic initiatives, and market positioning could reveal undervalued aspects that offer growth opportunities.\n",
      "\n",
      "3. **Implication of \"Spring\"**: The use of the word \"spring\" metaphorically suggests an expectation for rapid and significant appreciation in the stock's value, implying a bullish outlook. This hints at anticipated positive developments or catalysts that could drive the stock's performance.\n",
      "\n",
      "**Analysis for Long-Term Stability and Growth Potential:**\n",
      "\n",
      "- **Financial Health and Fundamentals**: As an institutional investor, the first step would be a detailed analysis of Starbucks’ financial health. This includes reviewing revenue growth, profit margins, cash flow stability, debt levels, and return on equity. Historically, Starbucks has shown robust financial performance with strong brand equity, which is a good indicator of financial stability.\n",
      "\n",
      "- **Growth Drivers**: Starbucks’ growth potential would be assessed by analyzing its expansion strategies, innovation in product offerings, penetration in emerging markets, and adaptability to changing consumer preferences. The company's focus on enhancing digital engagement, sustainability initiatives, and global store expansion are potential catalysts for growth.\n",
      "\n",
      "- **Market Position and Competitive Advantage**: Evaluating Starbucks' market position relative to competitors in the coffee industry and broader quick-service segment is crucial. Its brand recognition, premium product offerings, and global presence provide a competitive edge. However, competition from local coffee brands and new entrants could impact market share.\n",
      "\n",
      "- **Impact of External Factors**: Consideration of broader economic factors, such as changes in consumer spending behavior, inflation rates, and economic recovery post-pandemic, is essential. Regulatory changes and geopolitical tensions could also affect long-term stability.\n",
      "\n",
      "- **ESG Considerations**: As sustainability becomes increasingly important to investors, examining Starbucks’ commitments to environmental, social, and governance (ESG) factors will affect investor perception and possibly the stock’s long-term performance. Starbucks has made significant efforts in this area, which could enhance its reputation and customer loyalty.\n",
      "\n",
      "**Conclusion**: Given the long period of consolidation, if Starbucks demonstrates strong fundamentals and growth potential as outlined above, the stock could indeed be poised for a significant breakout, aligning with the optimistic sentiment conveyed in the message. As an institutional investor with a focus on long-term stability and growth, a detailed and thorough analysis following these guidelines would be essential before making substantial investment decisions in Starbucks’ stock.\n",
      "\n",
      "individual_investor_agent: Analyzing the implications of the message about Starbucks Corporation ($SBUX) involves a deeper look at its phrasing and the potential hints it provides about the market sentiment and stock's price movement, with an eye on short-term investment outcomes:\n",
      "\n",
      "1. **Understanding the Terms**:\n",
      "   - **Consolidating**: This term suggests that $SBUX's stock price has been trading within a specific range without significant upward or downward movement for an extended period. For short-term traders, a prolonged period of consolidation might indicate a buildup in pressure, possibly leading to a breakout or breakdown when a decisive market force or news acts on it.\n",
      "   - **Coiling**: Similar to consolidation, coiling implies even tighter trading ranges as the stock prepares for a more significant price movement. This is often associated with a spring-like action where following the consolidation phase, the stock could either jump up or down sharply.\n",
      "\n",
      "2. **Market Sentiment and Expectations**:\n",
      "   - The message indicates that the potential of $SBUX is \"underestimated\" by many. This could suggest that the general market sentiment might not have fully accounted for certain positive catalysts or financial health indicators that could later drive the stock's price up.\n",
      "   - The expression \"spring how\" might be a typographical error or shorthand on social platforms but it seems to imply an expectation of an upwards trajectory (springing up) soon.\n",
      "\n",
      "3. **Short-Term Price Impact**:\n",
      "   - **Immediate Action**: If you find the analysis convincing or align with the sentiment that the stock is about to breakout upwards, a strategy might involve buying shares or options betting on the stock's rise. This would aim to leverage the expected sharp movement to secure quick gains.\n",
      "   - **Watch for Catalysts**: For short-term gains, identifying upcoming events or financial reports that could act as catalysts for the price breakout is crucial. Positive earnings reports, new product launches, or favorable market conditions could serve as these catalysts.\n",
      "   - **Risks**: The other side of a consolidation is a potential breakdown. If the market has overestimated the stock's potential or external economic conditions worsen, the resulting move could be downwards.\n",
      "\n",
      "4. **Technical Analysis**:\n",
      "   - Before concluding on the action to take based on the message, a review of technical indicators like volume, moving averages, and RSI during the consolidation phase will provide additional insights into the stock's potential direction.\n",
      "\n",
      "5. **Immediate Gains or Losses**:\n",
      "   - Investments based on such speculative insights carry higher risk. The potential for immediate gains is there if the stock indeed breaks upwards following the consolidation, especially if acted upon before the wider market recognizes it. Conversely, the potential for immediate losses also exists if the stock breaks downwards or continues to consolidate, rendering short-term investment ineffective or unprofitable.\n",
      "\n",
      "In conclusion, as a short-term investor, it's essential to weigh the implications of the message against broader market analysis and be prepared for risky moves. Quick decisions and readiness to act on sudden market movements are necessary, but so is caution against possible misinterpretations of market setups or sentiments.\n",
      "\n",
      "rhetoric_agent: Analyzing the rhetorical style of the message provided involves breaking down the elements used by the speaker to convey their sentiment towards Starbucks stock ($SBUX).\n",
      "\n",
      "1. **Exaggeration**: The phrase \"has been consolidating and coiling for years\" uses exaggeration. The words \"years\" and \"coiling\" might be hyperbolic, emphasizing the duration and intensity of the stock's behavior, suggesting a significant build-up in potential energy or tension in the stock's price movement.\n",
      "\n",
      "2. **Understatement/Sarcasm**: The phrase \"I think many underestimate it\" can be seen as an understatement, which often relies on presenting an assertion as less significant than it is, thereby conveying a subtle tone of sarcasm or irony. This can imply that the speaker believes the underestimation is quite substantial, contrary to how casually the issue might be taken by others.\n",
      "\n",
      "3. **Metaphor**: The reference to the stock behavior as \"spring\" harnesses a metaphor of a tightly coiled spring, conjuring an image of something ready to release a substantial force. This metaphor is crucial as it reinforces the expectation of imminent and significant movement or change after the long period of coiling (consolidation).\n",
      "\n",
      "4. **Predictive/Assertive Tone**: The entire message carries an assertive tone, particularly with \"I think\" leading into a strong opinion about the general perception of the stock's potential. This sets the groundwork to convey that an opposing view held by the speaker is more informed or insightful.\n",
      "\n",
      "The overall rhetorical style contributes effectively to the sentiment of the message:\n",
      "- **Anticipation**: Created by the expectation of significant change after a prolonged period of consolidation.\n",
      "- **Contrarian optimism**: Implied by suggesting that others underestimate the stock, thereby positioning the speaker as holding an insight others lack.\n",
      "\n",
      "The employment of these rhetorical devices amplifies the impact of the sentiment, steering the reader towards a more engaged and perhaps optimistic perspective regarding $SBUX's future trajectory. The rhetorical style fosters intrigue and expectancy, underpinned by a confident assertion that the stock is bound for a notable change, contrasting with the broader market perception.\n",
      "\n",
      "dependency_agent: **Speaker’s Sentiment:** The speaker has a positive and hopeful sentiment towards the stock of Starbucks ($SBUX). The use of the term \"consolidating and coiling\" suggests they believe the stock has been stable and is building potential for a significant movement. The speaker also expresses an optimistic view that the stock is underestimated by many, hinting at an expectation of positive future performance or a breakout. The word \"spring\" metaphorically underscores their anticipation of a sudden and vigorous upward movement, much like a coiled spring releasing.\n",
      "\n",
      "aspect_agent: The sentiment expressed toward Starbucks ($SBUX) in the message is positive. The user suggests that the stock has been underappreciated (\"I think many underestimate it\") and implies potential for upward movement or significant activity with the terms \"consolidating and coiling\" and \"spring.\" These terms suggest an expectation of a positive breakout or growth, indicating a bullish outlook on the stock.\n",
      "\n",
      "reference_agent: The message consists of several distinct elements related to the stock of Starbucks (symbol: $SBUX) that impact the overall sentiment:\n",
      "\n",
      "1. **References to Time**: The phrase \"this stock has been consolidating and coiling for years\" directly references a time element by mentioning \"for years.\" This indicates that the stock has been in a phase of limited significant movement, likely trading within a certain range without a clear directional trend, for an extended period.\n",
      "\n",
      "2. **Sentiment Impact**: This time reference contributes to a sentiment of anticipation or buildup. The use of \"years\" suggests a prolonged period of stagnation or preparation, which in financial lingo (coiling) could signal an impending significant movement in stock price once it breaks out of this phase.\n",
      "\n",
      "3. **Lack of Price Points and External Factors**: The message does not offer specific price points or explicitly mention external economic factors, market conditions, or catalysts that could affect the stock’s performance. The absence of price details and external factors focuses the reader entirely on the historical performance and the author's opinion about the stock’s potential.\n",
      "\n",
      "4. **Overall Sentiment and Impact**: The overall sentiment of the message seems cautiously optimistic. The statement \"I think many underestimate it\" implies a belief that the general market or observers may not fully appreciate the stock's potential or expected movement. This could encourage a feeling of potential undervaluation or a forthcoming positive re-evaluation among readers.\n",
      "\n",
      "Based on these elements, the message suggests a positive outlook and a belief in forthcoming positive activity for Starbucks's stock, mainly based on its extended period of consolidation and underestimation by the market. This analysis anticipates a potentially significant change in the stock's movement, which could impact investor expectations and sentiment positively.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "content = \"$SBUX this stock has been consolidating and coiling for years. I think many underestimate it. spring how\"\n",
    "\n",
    "# Run each agent on the content\n",
    "responses = {\n",
    "    \"mood_agent\": mood_agent(content),\n",
    "    \"institutional_investor_agent\": institutional_investor_agent(content),\n",
    "    \"individual_investor_agent\": individual_investor_agent(content),\n",
    "    \"rhetoric_agent\": rhetoric_agent(content),\n",
    "    \"dependency_agent\": dependency_agent(content),\n",
    "    \"aspect_agent\": aspect_agent(content),\n",
    "    \"reference_agent\": reference_agent(content)\n",
    "}\n",
    "\n",
    "# Display the responses from each agent\n",
    "for agent, response in responses.items():\n",
    "    print(f\"{agent}: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3f3dd9-0bfd-442d-ac8a-1fd74210842a",
   "metadata": {},
   "source": [
    "# Mock Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bf73599-d05e-4915-b837-eee6bf44013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample financial message for sentiment analysis\n",
    "content = \"$SBUX this stock has been consolidating and coiling for years. I think many underestimate it. spring how\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b6d20dc-de06-4699-897a-68c05b1cc7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock agent responses to simulate natural language sentiment descriptions\n",
    "def mood_agent(content):\n",
    "    return \"The mood seems cautiously optimistic about future potential.\"\n",
    "\n",
    "def institutional_investor_agent(content):\n",
    "    return \"This message suggests a long-term positive outlook due to consolidation.\"\n",
    "\n",
    "def individual_investor_agent(content):\n",
    "    return \"Indicates potential for short-term gains but remains uncertain.\"\n",
    "\n",
    "def rhetoric_agent(content):\n",
    "    return \"The language implies underestimation by others, hinting at overlooked growth.\"\n",
    "\n",
    "def dependency_agent(content):\n",
    "    return \"The speaker seems to hold a positive perspective independently.\"\n",
    "\n",
    "def aspect_agent(content):\n",
    "    return \"Focuses specifically on $SBUX, suggesting stability and possible growth.\"\n",
    "\n",
    "def reference_agent(content):\n",
    "    return \"No explicit timeframes, but consolidation indicates a buildup for potential movement.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c4b2e87-a11a-42f9-b8d8-82b2519b3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect initial responses from each agent in a dictionary\n",
    "responses = {\n",
    "    \"mood_agent\": mood_agent(content),\n",
    "    \"institutional_investor_agent\": institutional_investor_agent(content),\n",
    "    \"individual_investor_agent\": individual_investor_agent(content),\n",
    "    \"rhetoric_agent\": rhetoric_agent(content),\n",
    "    \"dependency_agent\": dependency_agent(content),\n",
    "    \"aspect_agent\": aspect_agent(content),\n",
    "    \"reference_agent\": reference_agent(content)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "030a5628-175e-4e89-b5f4-1b82c34a0a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summative Agent with combined logic for proceeding to the next round if inconclusive\n",
    "def summative_agent(responses, max_rounds=2):\n",
    "    round_count = 0\n",
    "    consensus_reached = False\n",
    "    high_priority_agents = [\"institutional_investor_agent\", \"individual_investor_agent\"]\n",
    "    \n",
    "    # Store initial responses\n",
    "    sentiment_summary = {agent: response for agent, response in responses.items()}\n",
    "\n",
    "    while not consensus_reached and round_count < max_rounds:\n",
    "        # Step 1: Ask the model to summarize the collective sentiment based on agent responses\n",
    "        combined_responses = \"\\n\".join([f\"{agent}: {response}\" for agent, response in sentiment_summary.items()])\n",
    "        \n",
    "        # Ask GPT-4 to interpret the overall sentiment, allowing for Positive, Negative, Neutral, or Mixed\n",
    "        overall_sentiment = client.chat.completions.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=[{\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"Based on the following responses from various agents, summarize the overall sentiment as Positive, Negative, Neutral, or Mixed if no clear conclusion can be derived:\\n\\n{combined_responses}\"\n",
    "            }]\n",
    "        ).choices[0].message.content.strip().lower()\n",
    "        \n",
    "        # Check if a clear consensus is indicated by the response\n",
    "        if \"positive\" in overall_sentiment:\n",
    "            consensus_reached = True\n",
    "            final_sentiment = \"Positive\"\n",
    "        elif \"negative\" in overall_sentiment:\n",
    "            consensus_reached = True\n",
    "            final_sentiment = \"Negative\"\n",
    "        elif \"neutral\" in overall_sentiment:\n",
    "            consensus_reached = True\n",
    "            final_sentiment = \"Neutral\"\n",
    "        elif \"mixed\" in overall_sentiment or not consensus_reached:\n",
    "            # Inconclusive: proceed to the next round\n",
    "            round_count += 1\n",
    "            for agent, response in responses.items():\n",
    "                refined_response = client.chat.completions.create(\n",
    "                    model=\"gpt-4-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": f\"Refine your sentiment analysis by reviewing these responses:\\n{combined_responses}\\nOriginal response: {response}\"}\n",
    "                    ]\n",
    "                )\n",
    "                sentiment_summary[agent] = refined_response.choices[0].message.content\n",
    "\n",
    "    # If no consensus after max rounds, defer to high-priority agents for final decision\n",
    "    if not consensus_reached:\n",
    "        high_priority_responses = \"\\n\".join([f\"{agent}: {sentiment_summary[agent]}\" for agent in high_priority_agents if agent in sentiment_summary])\n",
    "        final_sentiment = client.chat.completions.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=[{\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"Summarize the final sentiment based on high-priority agents alone, as Positive, Negative, Neutral, or Mixed if no clear conclusion can be drawn:\\n{high_priority_responses}\"\n",
    "            }]\n",
    "        ).choices[0].message.content.strip().capitalize()\n",
    "\n",
    "    # Return the final sentiment and a detailed summary of agent responses\n",
    "    return {\n",
    "        \"final_sentiment\": final_sentiment,\n",
    "        \"summary\": sentiment_summary\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ab36fcf-fb24-464e-ad82-24a830e00dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Aggregated Sentiment: Positive\n",
      "Detailed Summary: {'mood_agent': 'The mood seems cautiously optimistic about future potential.', 'institutional_investor_agent': 'This message suggests a long-term positive outlook due to consolidation.', 'individual_investor_agent': 'Indicates potential for short-term gains but remains uncertain.', 'rhetoric_agent': 'The language implies underestimation by others, hinting at overlooked growth.', 'dependency_agent': 'The speaker seems to hold a positive perspective independently.', 'aspect_agent': 'Focuses specifically on $SBUX, suggesting stability and possible growth.', 'reference_agent': 'No explicit timeframes, but consolidation indicates a buildup for potential movement.'}\n"
     ]
    }
   ],
   "source": [
    "# Run the summative agent to determine final sentiment\n",
    "final_output = summative_agent(responses)\n",
    "print(\"Final Aggregated Sentiment:\", final_output[\"final_sentiment\"])\n",
    "print(\"Detailed Summary:\", final_output[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371320e9",
   "metadata": {},
   "source": [
    "# Financial Data Source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25488d18",
   "metadata": {},
   "source": [
    "### Financial News: GDELT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f1d67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Wapres berikan arahan strategis perkuat ekonom...\n",
       "1    Wapres ungkap strategi tingkatkan literasi - i...\n",
       "2    Wapres : Ekonomi Syariah Solusi Inklusif dan B...\n",
       "3                        报道 ： 中美金融工作组于8月15日至16日在上海举行会议\n",
       "4                                        财经时评｜金融亦是国之重器\n",
       "Name: title, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "url = \"https://api.gdeltproject.org/api/v2/doc/doc\"\n",
    "params = {\n",
    "    'query': '(economy OR finance)',  # Corrected query with parentheses\n",
    "    'mode': 'ArtList',\n",
    "    'format': 'JSON'\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0'\n",
    "}\n",
    "\n",
    "# Sending request to GDELT\n",
    "response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "# Verify the response and process the data\n",
    "if response.status_code == 200:\n",
    "    if response.text.strip():  # Check if the response is not empty\n",
    "        try:\n",
    "            data = response.json()\n",
    "            articles = pd.DataFrame(data.get('articles', []))\n",
    "            if 'title' in articles.columns:\n",
    "                # Displaying only the titles\n",
    "                display(articles['title'].head())\n",
    "            else:\n",
    "                print(\"No title information found in the response.\")\n",
    "        except ValueError:\n",
    "            print(\"Error decoding JSON. Response text:\", response.text)\n",
    "    else:\n",
    "        print(\"Received an empty response.\")\n",
    "else:\n",
    "    print(\"Error: \", response.status_code, \"\\nResponse Text: \", response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f65662",
   "metadata": {},
   "source": [
    "### SNS Financial Data: Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8da381b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "Unauthorized",
     "evalue": "401 Unauthorized\n89 - Invalid or expired token.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnauthorized\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Fetch tweets with the specified keyword\u001b[39;00m\n\u001b[0;32m     17\u001b[0m tweets \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtweet\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtweepy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCursor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_tweets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meconomy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtweet_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mextended\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtweets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreated_at\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtweet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreated_at\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtweet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscreen_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtweet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_text\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Convert to DataFrame\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hangyul Son\\TestingEnvironment\\LLMBasedTrading\\venv\\Lib\\site-packages\\tweepy\\cursor.py:86\u001b[0m, in \u001b[0;36mBaseIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hangyul Son\\TestingEnvironment\\LLMBasedTrading\\venv\\Lib\\site-packages\\tweepy\\cursor.py:286\u001b[0m, in \u001b[0;36mItemIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpage_index \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Reached end of current page, get the next page...\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpage_iterator)\n",
      "File \u001b[1;32mc:\\Users\\Hangyul Son\\TestingEnvironment\\LLMBasedTrading\\venv\\Lib\\site-packages\\tweepy\\cursor.py:86\u001b[0m, in \u001b[0;36mBaseIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hangyul Son\\TestingEnvironment\\LLMBasedTrading\\venv\\Lib\\site-packages\\tweepy\\cursor.py:167\u001b[0m, in \u001b[0;36mIdIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 167\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRawParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     model \u001b[38;5;241m=\u001b[39m ModelParser()\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m    170\u001b[0m         data, api \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m,\n\u001b[0;32m    171\u001b[0m         payload_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mpayload_list,\n\u001b[0;32m    172\u001b[0m         payload_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mpayload_type\n\u001b[0;32m    173\u001b[0m     )\n\u001b[0;32m    174\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m    175\u001b[0m         data, api \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m,\n\u001b[0;32m    176\u001b[0m         payload_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mpayload_list,\n\u001b[0;32m    177\u001b[0m         payload_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mpayload_type\n\u001b[0;32m    178\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Hangyul Son\\TestingEnvironment\\LLMBasedTrading\\venv\\Lib\\site-packages\\tweepy\\api.py:33\u001b[0m, in \u001b[0;36mpagination.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(method)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hangyul Son\\TestingEnvironment\\LLMBasedTrading\\venv\\Lib\\site-packages\\tweepy\\api.py:46\u001b[0m, in \u001b[0;36mpayload.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayload_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m payload_list\n\u001b[0;32m     45\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayload_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m payload_type\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hangyul Son\\TestingEnvironment\\LLMBasedTrading\\venv\\Lib\\site-packages\\tweepy\\api.py:1146\u001b[0m, in \u001b[0;36mAPI.search_tweets\u001b[1;34m(self, q, **kwargs)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;129m@pagination\u001b[39m(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;129m@payload\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_results\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_tweets\u001b[39m(\u001b[38;5;28mself\u001b[39m, q, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"search_tweets(q, *, geocode, lang, locale, result_type, count, \\\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;124;03m                     until, since_id, max_id, include_entities)\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;124;03m    .. _Twitter's documentation on the standard search API: https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/overview\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msearch/tweets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeocode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlang\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresult_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muntil\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msince_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minclude_entities\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hangyul Son\\TestingEnvironment\\LLMBasedTrading\\venv\\Lib\\site-packages\\tweepy\\api.py:269\u001b[0m, in \u001b[0;36mAPI.request\u001b[1;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequest(resp)\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n\u001b[1;32m--> 269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Unauthorized(resp)\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Forbidden(resp)\n",
      "\u001b[1;31mUnauthorized\u001b[0m: 401 Unauthorized\n89 - Invalid or expired token."
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Set your keys and tokens (replace placeholders with your actual credentials)\n",
    "consumer_key = \"YOUR_CONSUMER_KEY\"\n",
    "consumer_secret = \"YOUR_CONSUMER_SECRET\"\n",
    "access_token = \"YOUR_ACCESS_TOKEN\"\n",
    "access_token_secret = \"YOUR_ACCESS_TOKEN_SECRET\"\n",
    "\n",
    "# Authenticate with Twitter API\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Fetch tweets with the specified keyword\n",
    "tweets = []\n",
    "for tweet in tweepy.Cursor(api.search_tweets, q=\"economy\", lang=\"en\", tweet_mode=\"extended\").items(10):\n",
    "    tweets.append({'created_at': tweet.created_at, 'user': tweet.user.screen_name, 'text': tweet.full_text})\n",
    "\n",
    "# Convert to DataFrame\n",
    "tweets_df = pd.DataFrame(tweets)\n",
    "\n",
    "# Display the first few tweets\n",
    "display(tweets_df[['created_at', 'user', 'text']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b773ea",
   "metadata": {},
   "source": [
    "### Financial Forum: Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3292b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv(\"CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"CLIENT_SECRET\"),\n",
    "    password=os.getenv(\"PASSWORD\"),  # Replace with your Reddit account password\n",
    "    user_agent=os.getenv(\"USER_AGENT\"),\n",
    "    username=os.getenv(\"USERNAME\").strip()\n",
    ")\n",
    "\n",
    "# Verify Reddit instance is connected\n",
    "print(f\"Connected as: {reddit.user.me()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab2014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch posts from a subreddit as a test\n",
    "subreddit = reddit.subreddit(\"financialindependence\")\n",
    "for submission in subreddit.hot(limit=5):\n",
    "    print(submission.title)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
